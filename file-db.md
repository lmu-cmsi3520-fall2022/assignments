**CMSI 3520** Database Systems, Fall 2021

# Assignment 0927
Before diving fully into database systems per se, we make one stopover ‚Äúunder the hood‚Äù by looking at data management in terms of working with files alone. The premise here is that all database systems, regardless of model, philosophy, or generation, ultimately store their data in files. Thus, it is of value to explore what it takes to work with files _directly_‚Äîin a way, to write the very beginnings of your own database system.

## Background Reading
The Elmasri & Navathe book touches on this conceptually in their Chapter 1 section on ‚ÄúAdvantages of Using the DBMS Approach.‚Äù If you want a peek into how database management systems _do_ organize their data files in order to do what they do efficiently, you can skim Part 7 _File Structures, Hashing, Indexing, and Physical Database Design_ to get an idea of how this is done. Think of this assignment as a microcosm of that material.

Continue to draw inspiration from the [Kaggle](https://www.kaggle.com/datasets) and [Awesome Public Datasets](https://github.com/awesomedata/awesome-public-datasets) collections for this assignment‚Äîand this time, keep a closer eye on datasets that have files which you can actually work with along the lines of this assignment. As before the [Netflix Prize](https://www.kaggle.com/netflix-inc/netflix-prize-data) dataset is used as the case study for the assignment‚Äôs accompanying examples‚Äîyou may not use it for your own submission, but by all means download these files and try out [the given examples](./netflix-prize-file-example) for yourself.

Direct assistance for the action items in this assignment can be found (among other places) in:
* [Finding Things](https://swcarpentry.github.io/shell-novice/07-find/) on the command line
* Manual pages for [grep](https://man7.org/linux/man-pages/man1/grep.1p.html) and [wc](https://man7.org/linux/man-pages/man1/wc.1p.html)
* [A tutorial](https://www.grymoire.com/Unix/Awk.html) on [awk](https://man7.org/linux/man-pages/man1/awk.1p.html)

Also of use would be programming references for I/O and file processing libraries of whatever programming language you might choose, such as:
* [Python](https://docs.python.org/3.7/tutorial/inputoutput.html#reading-and-writing-files) (take a look at their [csv](https://docs.python.org/3.7/library/csv.html) library too)
* [NodeJS](https://nodejs.org/api/fs.html)‚Äîparticularly handy if your dataset‚Äôs files are in [JSON format](https://stackabuse.com/reading-and-writing-json-files-with-node-js/)
* [Java](https://docs.oracle.com/javase/tutorial/essential/io/file.html)‚Äîjust don‚Äôt tell Toal (lest you become a‚Ä¶tattle-Toal?)
* (though I doubt any of you will pick this one) [C](https://en.wikipedia.org/wiki/C_file_input/output)‚Äîunless you‚Äôre taking this as a challenge and want to legit say [‚ÄúHold my avocado ü•ë‚Äù](https://www.thrillist.com/news/nation/hold-my-avocado-meme-origin)

Of course, for technologies like these, you‚Äôre likely to find a lot of additional supplements on the web.

## For Submission: File Database Mini-Stack
For this assignment, give yourselves and your groups a taste of what it would be like to work with data at a file level by taking a stab at performing the database operations described below.

### Warm Up to the Challenge: _netflix-practice.md_
Walk through the [Netflix Prize file database mini-stack case study](./netflix-prize-file-example)‚Äîideally together as a group, so you can help each other through each example‚Äîand do a little prep by doing some freeform exploration of that data using the techniques shown therein. Ideally, everyone in the group can download and preprocess the data firsthand; if this is not feasible for some, designate one or more group members to serve as ‚Äúhosts‚Äù for your work, and collaborate around a screenshare with them.

In a Markdown file on your repository called _netflix-practice.md_, do the following:
1. Write up two (2) movie queries‚Äîthings like movies with certain titles or title patterns, movies released on one or more given years, etc. Provide those queries and show their results (or a subset of them, if there are too many to list).
2. Pick a viewer at random and build their complete ‚Äúreview profile‚Äù‚Äîactually track down the titles/years of the movies they reviewed and how they rated them. Provide the commands used to build this profile and show the results. State conclusions that your group thinks can be drawn about that viewer‚Äôs preferences and tastes.
3. Pick a movie at random and collate its review scores. Provide the commands used to gather this data and show the results. Can you draw any conclusions about the quality of this movie based on the review scores that it received?

### Let There Be‚Ä¶Data! (_about.md_, _.gitignore_)
After you‚Äôve gotten some practice with the Netflix Prize data, you‚Äôll now need to work with another dataset in all its glory (not just mimicking its structure), so choose well! Pre-visualize the kinds of files that you can work with based on the requested operations, alongside the language that you would be inclined to use for the operations that call for a little programming. Make sure to keep that in mind alongside, of course, also still picking a dataset whose core content is interesting to you.

This assignment is most effective when you implement the requested operations on that dataset _in its entirety_ (just like with the Netflix Prize case study)‚Äîso yes you‚Äôll have to be conscious of how much disk space you have available‚Äîand get to know how the files are organized, formatted, and structured. Ideally, everyone in the group will be able to work with the files directly; however not everyone may have enough capacity to work with the entire dataset on their local computer so please be open to projecting or sharing your screen and allowing for some teammates to drive in order to give everyone that firsthand experience.

In any case, describe your dataset and potential applications for it in a file called _about.md_. This can be very similar to the _about.md_ that you wrote for the database fiddle assignment. Make sure that _about.md_ also has links to the actual dataset, for anyone who would like to download a copy for themselves.

Whatever you do, do _not_ commit the datasets to GitHub. This is one case where GitHub isn‚Äôt a good fit.

To guarantee that this does not accidentally happen, _edit the `.gitignore` file_ so that it makes your repository ignore the files that comprise your chosen dataset.

### Feel the Power: _queries.md_
Once you have the data at your fingertips, it‚Äôs time to play database. Seek to implement the following operations. Refer back to the examples in the [netflix-prize-file-example](./netflix-prize-file-example) folder as needed. Just remember that _datasets will differ from each other_, so don‚Äôt limit yourself exclusively to what you see in the case study. In particular, note that the case study uses Python for custom programming work‚Äîthis will not necessarily be the best fit for the dataset that you choose.

As before, it is also useful to contextualize things by envisioning an application that would use your chosen dataset. Having such an application in mind will help fuel ideas for the specific operations to implement in the following categories. Place query descriptions and commands in a file called _queries.md_ and commit relevant source code directly to the repository (referring to them as needed in _queries.md_):

1. Query by pure command (`grep`, `awk`)
2. Count query by pure command (`grep`, `awk`, `wc`)
3. Query by a program that scans the data file(s)
4. Query by pure command facilitated by pre-processing (with accompanying preprocessor of course)
5. ‚ÄúCompound‚Äù query that requires a manual combination of commands or programs

### Take Stock of Your Mini-Stack: _report.md_
Finally, finish up the exercise by writing a small technical report on everything that you did. Call this document _report.md_ and answer the following questions:
1. Which operations/commands/programs were the most difficult to implement? Which were easiest? Provide brief rationales for your responses.
2. In what way do the size and ordering of your data files affect the speed of an individual operation?
    - To support your answer, use the `time` command to get an objective reading for how long certain operations take
    - Choose your timed operations in a way that illustrates how size and ordering affects performance
3. Is there a correlation between the ease of implementation and performance? (i.e., are the hardest operations to implement always the slowest ones? vice versa? or is there no relationship at all?)

## Operational Directives/Suggestions
- Make sure to divide the implementation work relatively evenly within your group. Most groups have four (4) members and you will notice that there are eight (8) total ‚Äúcoding‚Äù tasks (three for Netflix, five for your dataset). Thus, letting individual group members ‚Äúown‚Äù around two (2) tasks each will help spread the load. Of course you can all help each other as needed, but let each person take point on two items.
- Once more, do _not_ commit the original files to the repository‚Äîthey may be too large for that. Provide links instead. Edit _.gitignore_ to avoid accidental commits.
- Not everyone‚Äôs computer might have enough storage or other capacity‚ÄîAWS is an option but watch your credits; or, designate someone as the ‚Äúhost‚Äù for doing work and find ways to collaborate over a screenshare and (friendly) remote control of a classmate‚Äôs screen.

## How to Turn it In
Commit everything to GitHub. Reiterating the deliverables, they are:
- [_netflix-practice.md_](#warm-up-to-the-challenge-netflix-practicemd)
- [_about.md_](#let-there-bedata-aboutmd-gitignore)
- [_.gitignore_](#let-there-bedata-aboutmd-gitignore) (revised from what is already provided)
- [_queries.md_](#feel-the-power-queriesmd)
- Custom [file-processing/querying code](#feel-the-power-queriesmd)
- [_report.md_](#take-stock-of-your-mini-stack-reportmd)

Review the instructions in the deliverables‚Äô respective sections to see what goes in them.

## Specific Point Allocations
This assignment is scored according to outcomes _1a_, _1d_, _2b_, _3c_, _3d_, and _4a_ to _4f_ in the [syllabus](https://dondi.lmu.build/fall2021/cmsi3520/cmsi3520-fall2021-syllabus.pdf). For this particular assignment, graded categories are as follows:

| Category | Points | Outcomes |
| -------- | -----: | -------- |
| _netflix-practice.md_ correctly implements the requested operations | 5 points each, 15 points total | _1a_, _2b_, _3c_, _4a_ |
| _about.md_ | 10 points total | _1a_, _1d_, _4c_ |
| ‚Ä¢ Includes link to the dataset‚Äôs files | 3 points | |
| ‚Ä¢ Describes the dataset and possible applications well | 7 points | |
| _.gitignore_ correctly prevents accidental commits of dataset files | 5 points | _4a_ |
| _queries.md_ correctly implements the requested operations | 7 points each, 35 points total | _1d_, _2b_, _3c_, _4a_ |
| Custom file-processing/querying code works as intended | 10 points each, 20 points total | _1d_, _2b_, _3d_, _4a_ |
| _report.md_ answers the questions well | 5 points each, 15 points total | _1a_, _4c_ |
| ‚Ä¢ Objective data supplied via `time` | deduction if not provided | |
| Hard-to-maintain or error-prone code | deduction only | _4b_ |
| Hard-to-read code | deduction only | _4c_ |
| Version control | deduction only | _4e_ |
| Punctuality | deduction only | _4f_ |
| **Total** | **100** |

Note that inability to compile and run any code to begin with will negatively affect other criteria, because if we can‚Äôt run your code (or commands), we can‚Äôt evaluate related remaining items completely.
